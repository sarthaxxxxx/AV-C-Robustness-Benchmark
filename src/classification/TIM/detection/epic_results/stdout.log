[01/07 05:28:58] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:29:01] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:29:01] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:29:01] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb
[01/07 05:29:44] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:29:49] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:29:49] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:29:49] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data
[01/07 05:30:02] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:30:06] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:30:06] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:30:06] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:34:09] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:34:11] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:34:11] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:34:11] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:34:23] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:34:26] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:34:26] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:34:26] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:36:16] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:36:19] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:36:19] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:36:19] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:37:57] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:38:02] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:38:02] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:38:02] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_noun/data.pkl
[01/07 05:39:24] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:39:28] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:39:28] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:39:28] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:41:01] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:41:06] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:41:06] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:41:06] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:42:54] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:42:58] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:42:58] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:42:58] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 05:43:44] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:43:49] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:43:49] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:43:49] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb.pth
[01/07 05:46:28] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:46:31] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:46:31] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:46:31] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb.pth
[01/07 05:46:54] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:46:58] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:46:58] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:46:58] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb
[01/07 05:47:09] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 05:47:14] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 05:47:14] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 05:47:14] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb/data.pkl
[01/07 06:01:10] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 06:01:14] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 06:01:14] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 06:01:14] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb.pth.tar
[01/07 06:01:39] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 06:01:44] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 06:01:44] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 06:01:44] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb.pth.tar
[01/07 06:01:44] loader.py - L 13: Creating val loader for modality: visual
[01/07 06:01:44] sliding_window.py - L 58: Constructing dataset for split : val
[01/07 06:01:44] sliding_window.py - L 87: Caching Features
[01/07 06:01:44] sliding_window.py - L122: Loading visual data
[01/07 06:46:44] tim.py - L 58: Building audio_visual Transformer with 1024-D, 8 heads, and 6 layers.
[01/07 06:46:47] extract_feats.py - L 35: TIM(
  (time_mlp): Sequential(
    (0): Linear(in_features=2, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): ReLU()
    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (feature_encoding): AudioVisualFeatureEncoding(
    (visual_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (audio_embedder): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=32, out_features=512, bias=True)
      (2): GELU(approximate='none')
      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (cls_head): VisualCLSHead(
    (fc_visual_action): Linear(in_features=1024, out_features=97, bias=True)
  )
  (reg_head): VisualRegHead(
    (fc_visual_action): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=512, bias=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=2, bias=True)
      (5): Sigmoid()
    )
  )
  (backbone): TransformerEncoder(
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=1024, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=1024, bias=True)
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (drloc_mlp): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
[01/07 06:46:47] extract_feats.py - L 37: Output dir : ../epic_results
[01/07 06:46:47] checkpoint.py - L 12: Loading Model from Path: /home/jovyan/workspace/AV-C-Robustness-Benchmark/src/classification/TIM/epic_100_verb.pth.tar
[01/07 06:46:47] loader.py - L 13: Creating val loader for modality: visual
[01/07 06:46:47] sliding_window.py - L 58: Constructing dataset for split : val
[01/07 06:46:47] sliding_window.py - L 87: Caching Features
[01/07 06:46:47] sliding_window.py - L122: Loading visual data
